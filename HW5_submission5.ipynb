{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjKgy+yUIBvSCToJaDlGfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grfa5712/CSPB3202-HW5/blob/main/HW5_submission5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4updHdhnUeFA"
      },
      "outputs": [],
      "source": [
        "#Remember to switch hardware accelerator to T4 GPU in Colab\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Before proceeding, generate a token from Kaggle and save to local drive; use files.upload to navigate to and upload kaggle.json file from local drive to Colab\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "nr_1b1xkUnSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "metadata": {
        "id": "9ccVilKvUv4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "JOeL8VKSU4Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "2geeLCUWVSuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c histopathologic-cancer-detection\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "gwQ0BFcVVcBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/histopathologic-cancer-detection.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content/histopathologic_dataset')"
      ],
      "metadata": {
        "id": "NviVGFb5Vf44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries and tools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import RandomFlip, RandomZoom, RandomRotation\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "\n",
        "sns.set_style(\"darkgrid\")"
      ],
      "metadata": {
        "id": "X0hsXx7DWZzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Access paths and .csv files in histopathologic_dataset folder\n",
        "testPath = './histopathologic_dataset/test'\n",
        "trainPath = './histopathologic_dataset/train'\n",
        "trainData = pd.read_csv('./histopathologic_dataset/train_labels.csv')\n",
        "sampleSubmission = pd.read_csv('./histopathologic_dataset/sample_submission.csv')\n"
      ],
      "metadata": {
        "id": "sFVf8Tg0tHeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display format of trainData (id and label)\n",
        "trainData.head()"
      ],
      "metadata": {
        "id": "H26OcZYlX2m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use info to check for null values\n",
        "trainData.info()"
      ],
      "metadata": {
        "id": "CKCv4yeVzjNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize counts with histogram\n",
        "sns.countplot(x=trainData['label']).set(xlabel='Labels (0 = No Tumor, 1 = Tumor)', ylabel= 'Count', title='Counts by Label')"
      ],
      "metadata": {
        "id": "MdIgICLQ0zCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print count for each label\n",
        "print(pd.DataFrame(data={'Counts by Label': trainData['label'].value_counts()}))"
      ],
      "metadata": {
        "id": "wGplhayt0QpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pie chart visualization based on labels\n",
        "labels_count = trainData.label.value_counts()\n",
        "\n",
        "%matplotlib inline\n",
        "plt.pie(labels_count, labels=['No Tumor', 'Tumor'], startangle=180,\n",
        "        autopct='%1.1f', shadow=True)\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wPwKrgpH8SoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display samples from both no tumor and tumor sets to show difficulty in differentiating by eye\n",
        "\n",
        "imageCount = 4\n",
        "\n",
        "trainData[\"path\"] = trainData[\"id\"].apply(lambda x: os.path.join(\"./histopathologic_dataset/train\", str(x) + \".tif\"))\n",
        "imageLabel0 = trainData[trainData[\"label\"] == 0]\n",
        "imageLabel1 = trainData[trainData[\"label\"] == 1]\n",
        "\n",
        "for i in range(imageCount):\n",
        "    image = plt.imread(imageLabel0[\"path\"].iloc[i])\n",
        "\n",
        "    plt.subplot(2, imageCount, i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"No Tumor\")\n",
        "\n",
        "for i in range(imageCount):\n",
        "    image = plt.imread(imageLabel1[\"path\"].iloc[i])\n",
        "\n",
        "    plt.subplot(2, imageCount, imageCount + i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Tumor\")\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2uBHQKlH426L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create constant for batch size to use in model below\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "c0KqVMfdSnX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare data for training, select random sample from both 0 and 1 labels, and then shuffle\n",
        "def append_tif(string):\n",
        "  return string+\".tif\"\n",
        "\n",
        "trainData['id'] = trainData[\"id\"].apply(append_tif)\n",
        "trainData['label'] = trainData['label'].astype(str)"
      ],
      "metadata": {
        "id": "kfsWiHOC_SBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData0 = trainData[trainData['label']=='0'].sample(20000,random_state=42)\n",
        "trainData1 = trainData[trainData['label']=='1'].sample(20000,random_state=42)\n",
        "trainData = pd.concat([trainData0, trainData1], axis=0).reset_index(drop=True)\n",
        "trainData = shuffle(trainData, random_state=42)\n",
        "trainData['label'].value_counts()"
      ],
      "metadata": {
        "id": "g_KlT1LPIXNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize training data and split into training and validation sets\n",
        "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)"
      ],
      "metadata": {
        "id": "d4Ppn_DcBJds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate training data\n",
        "trainGenerator = datagen.flow_from_dataframe(\n",
        "    dataframe=trainData,\n",
        "    directory=trainPath,\n",
        "    x_col='id',\n",
        "    y_col='label',\n",
        "    subset='training',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=42,\n",
        "    class_mode='binary',\n",
        "    target_size=(96,96)\n",
        ")"
      ],
      "metadata": {
        "id": "hfQcDvmwBjj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate validation data\n",
        "validGenerator = datagen.flow_from_dataframe(\n",
        "    dataframe=trainData,\n",
        "    directory=trainPath,\n",
        "    x_col='id',\n",
        "    y_col='label',\n",
        "    subset='validation',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=42,\n",
        "    class_mode='binary',\n",
        "    target_size=(96,96)\n",
        ")"
      ],
      "metadata": {
        "id": "Yo1nxf4GDvhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', ))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.build(input_shape=(BATCH_SIZE, 96, 96, 3))\n",
        "\n",
        "ROC = tf.keras.metrics.AUC()\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ST-H0x_4Qt8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', metrics=['accuracy', ROC], optimizer=RMSprop(learning_rate=0.001))"
      ],
      "metadata": {
        "id": "CWOfrpHYLCqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "historyModel = model.fit_generator(\n",
        "                        trainGenerator,\n",
        "                        epochs = 10,\n",
        "                        validation_data = validGenerator)"
      ],
      "metadata": {
        "id": "wxNHQte-aBnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = historyModel.history\n",
        "print(history_dict.keys())"
      ],
      "metadata": {
        "id": "6x7ZBFlgOhg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot metrics for model\n",
        "plt.plot(historyModel.history['accuracy'])\n",
        "plt.plot(historyModel.history['val_accuracy'])\n",
        "plt.title('Accuracy per Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validate'], loc='lower right')\n",
        "plt.show();\n",
        "\n",
        "plt.plot(historyModel.history['loss'])\n",
        "plt.plot(historyModel.history['val_loss'])\n",
        "plt.title('Loss per Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validate'], loc='upper right')\n",
        "plt.show();\n",
        "\n",
        "plt.plot(historyModel.history['auc'])\n",
        "plt.plot(historyModel.history['val_auc'])\n",
        "plt.title('AUC ROC per Epoch')\n",
        "plt.ylabel('ROC')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validate'], loc='lower right')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "8NuILea0j-vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dataframe to run the predictions\n",
        "testDf = pd.DataFrame({'id':os.listdir(testPath)})\n",
        "testDf.head()"
      ],
      "metadata": {
        "id": "-I4SkdpzkhXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare test data for submission\n",
        "datagenTest = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "testGenerator = datagenTest.flow_from_dataframe(\n",
        "    dataframe=testDf,\n",
        "    directory=testPath,\n",
        "    x_col='id',\n",
        "    y_col=None,\n",
        "    target_size=(96,96),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    class_mode=None)"
      ],
      "metadata": {
        "id": "FQv7oNaRkyrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(testGenerator, verbose=1)"
      ],
      "metadata": {
        "id": "4QntaXcelBPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare dataframe for submission\n",
        "predictions = np.transpose(predictions)[0]\n",
        "submissionDf = pd.DataFrame()\n",
        "submissionDf['id'] = testDf['id'].apply(lambda x: x.split('.')[0])\n",
        "submissionDf['label'] = list(map(lambda x: 0 if x < 0.5 else 1, predictions))"
      ],
      "metadata": {
        "id": "6DM348r5lX0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissionDf.head()"
      ],
      "metadata": {
        "id": "Qbc8QQ9gzugM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print test prediction counts\n",
        "submissionDf['label'].value_counts()"
      ],
      "metadata": {
        "id": "TosBpIdfmG9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to csv to upload to Kaggle\n",
        "submissionDf.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "UcPihYdfmM7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R0T3TefXJxsr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}